\subchapter
{Application profiling}
{Objectives:
  \begin{itemize}
    \item Visualizing application heap using {\em Massif}.
    \item Profiling an application with {\em Cachegrind}, {\em Callgrind} and
          {\em KCachegrind}.
    \item Analyzing application performance with {\em perf}.
  \end{itemize}
}

\section{Massif}

Massif is really helpful to understand what is going on the memory allocation
side of an application. Compile the \code{heap_profile} example that we did provide
using the following command:

\begin{bashinput}
$ cd /home/<user>/debugging-labs/nfsroot/root/heap_profile
$ make
\end{bashinput}

Once compile, on the target run it under massif using the following command:

\begin{bashinput}
$ cd /root/heap_profile
$ valgrind --tool=massif --time-unit=B ./heap_profile
\end{bashinput}

NOTE: we use \code{--time-unit=B} to set the X axis to be based on the allocated
size.

Once done, a \code{massif.out.<pid>} file will be created. This file can be
displayed with \code{ms_print}. Based on the result, can you answer the
following questions:
\begin{itemize}
  \item What is the peak allocation size of this program ?
  \item How much memory was allocated during the program lifetime ?
  \item Do we have memory leaks at the end of execution ?
\end{itemize}

Note: \code{heaptrack} is not available on buildroot but is available on debian.
You can try the same experience using heaptrack on your computer and visualizing
the results with \code{heaptrack_gui}.

\section{Cachegrind \& Callgrind}

Cachegrind and Callgrind allows to profile a userspace application by
simulating the processor that will run it. In order to analyze our application
and understand were the time is spent, we are going to profile it with both
tools.

In order to profile the application using the \code{callgrind} tool. Our program
takes two parameters, an input png and an output one. We provided a
\code{tux_small.png} which can be used as an input file. First let's compile it using
the following commands:

\begin{bashinput}
$ cd /home/<user>/debugging-labs/nfsroot/root/app_profiling
$ make
\end{bashinput}

We are going to profile cache usage using Cachegrind with the following command:

\begin{bashinput}
$ valgrind --tool=cachegrind ./png_convert tux_small.png out.png
\end{bashinput}

The execution will take some times and a \code{cachegrind.out.<pid>} will be
generated. Once finished, on the host, fix the permissions on the
\code{callgrind.out.*} file to be able to open it with \code{Kcachegrind}:

\begin{bashinput}
$ sudo chown <user>:<user> cachegrind.out.*
\end{bashinput}

Analyze the results with \code{Kcachegrind} in order to understand the
function that generates most of the D cache miss time. 

Based on that result, modify the program to be more cache efficient. Run again
the cachegrind analysis to check that the modifications were actually effective.

We also profile the execution time using callgrind with 

\begin{bashinput}
$ valgrind --tool=callgrind ./png_convert tux_small.png out.png
\end{bashinput}

Again, on the host platform, fix the permissions of the file using:
\begin{bashinput}
$ sudo chown <user>:<user> callgrind.out.*
\end{bashinput}

Again, analyze the results using \code{Kcachegrind}. This time, the view is
different and allow to display all the call graphs

Looking at the results, it seems like our conversion function is
actually taking a negligible time. However, valgrind simulate the program with
an "ideal" cache. In real life, the processor is often used by other
applications and the kernel also takes some time to execute which leads to cache
disturbance. Hence, callgrind is a good tool to optimize applications based on
CPU time

\section{Perf}

In order to have a better view of the performance of our program in a real
system, we will use \code{perf}. First of all, we will record our program
execution using the \code{perf record} command.

\begin{bashinput}
$ perf record ./png_convert tux_small.png out.png
\end{bashinput}

Once recorded, a \code{perf.data} file will be generated. This file will
contain the traces that have been recorded. These traces can be analyzed using
\code{perf report}. You will quickly notice that the output is not the same as
valgrind because it displays a time spent per function (excluding function
calls inside them). This allows to find which function takes most of the
execution time. In order to compare this output to the valgrind one, we can
run perf and also record the callgraph using the \code{--call-graph} option.

\begin{bashinput}
$ perf record --call-graph dwarf ./png_convert tux_small.png out.png
\end{bashinput}

We specify that we want to record the call graph using the DWARF information
that are contained in ELF file (compiled with \code{-g}). Once recorded, display
the results with \code{perf report} and compare them with callgrind ones:


\begin{bashinput}
$ perf report --symfs=/home/<user>/debugging-labs/buildroot/output/staging/
   -k /home/<user>/debugging-labs/buildroot/output/build/linux-5.13/vmlinux
   ./png_convert tux_small.png out.png
\end{bashinput}
